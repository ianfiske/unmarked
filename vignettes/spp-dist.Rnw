<<echo=false>>=
options(width=70)
options(continue=" ")
@

\documentclass[a4paper]{article}
\usepackage[OT1]{fontenc}
\usepackage{Sweave}
\usepackage[authoryear,round]{natbib}
\usepackage{fullpage}
\usepackage{verbatim}

\usepackage[a4paper, hmargin={2cm,2cm}, vmargin={2cm,2cm}]{geometry}


\bibliographystyle{ecology}

\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=2em}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=2em}
\DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=2em}
\fvset{listparameters={\setlength{\topsep}{0pt}}}
\renewenvironment{Schunk}{\vspace{\topsep}}{\vspace{\topsep}}

%%\VignetteIndexEntry{Species distributions}

\title{Modeling and mapping species distributions}
\author{Richard Chandler}


\begin{document}

\maketitle

\abstract{
A species' distribution is naturally characterized by either
occurrence probability or population density, defined for all
locations in some spatial domain. Defining distribution in terms of
these parameters %These definitions of species distribution
avoids the ambiguity surrounding the indices of occurrence
or abundance produced by many presence-only algorithms. The
\texttt{unmarked} package contains methods of fitting
occurrence and abundance models, and can be used to
produce distribution maps with the help of \textbf{R}'s GIS
capabilities,
%, such as the \texttt{raster} package
%\citep{hijmans_vanEtten:2012}
as is demonstrated in this vignette.
Unlike many other tools for modeling
species distributions, the models in \texttt{unmarked} account for
bias due to spatial or temporal heterogeneity in detection
probability. Furthermore, \texttt{unmarked} includes models
of population dynamics, allowing one to map quantities
such as local colonization or extinction probability.
}

\section*{Mapping Population Density}

Although distribution is typically described in terms of
ocurrence probability, density is a better descriptor for several
reasons. First, density can be readily converted to abundance for any
region of interest; whereas occurrence probability does not scale with
area.

<<echo=false>>=
library(unmarked)
library(raster)
@


<<>>=
data(issj)
data(cruz)

elev <- rasterFromXYZ(cruz[,c("x","y","elevation")],
     crs="+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")

plot(elev, col=terrain.colors(100))
points(issj[,c("x","y")], cex=0.5)
@




<<>>=
covs <- scale(issj[,c("elevation", "forest", "chaparral")])

area <- pi*300^2 / 10000
covs <- cbind(covs, area)

jayumf <- unmarkedFrameDS(y=as.matrix(issj[,1:3]),
                          siteCovs=as.data.frame(covs),
                          dist.breaks=c(0,100,200,300),
                          unitsIn="m", survey="point")

fm1 <- distsamp(~chaparral ~chaparral + elevation + offset(area), jayumf,
                output="abund")
fm1

@

<<>>=

elev <- rasterFromXYZ(cruz[,c("x","y","elevation")],
     crs="+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")
forest <- rasterFromXYZ(cruz[,c("x","y","forest")],
     crs="+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")
chap <- rasterFromXYZ(cruz[,c("x","y","chaparral")],
     crs="+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")
area.raster <- chap
values(area.raster) <- 300*300/10000 # area of a grid pixel

attr(covs, "scaled:center")
attr(covs, "scaled:scale")

elev.s <- (elev-202)/125
forest.s <- (forest-0.0673)/0.137
chap.s <- (chap-0.270)/0.234


habitat <- stack(elev.s, forest.s, chap.s, area.raster)
layerNames(habitat) <- c("elevation", "forest", "chaparral", "area")
spplot(habitat[[1:3]], layout=c(1,3), colorkey=FALSE,
       col.regions=terrain.colors(100))

@




<<>>=
E <- predict(fm1, type="state", newdata=habitat)
plot(E)

cellStats(E[["Predicted"]], "sum")



@



\begin{comment}



\section*{Mapping Occurrence Probability}

In this example, we fit the dynamic occupancy model of
\citep{mackenzie_estimating_2003} to data on the European crossbill
(\emph{Loxia curvirostra}) collected in 267 1-km$^2$ sample
quadrats in Switzerland, 1999-2007 \citep{schmid_etal:2004}.
We then use the model to compute the expected probability of
occurrence at each pixel in a raster defining the Swiss
landscape. %Computing confidence intervals for the predictions is also
%demonstrated, although the delta method approximation used is very
%time consuming when the number of pixels is high.

First we load the crossbill data\footnote{This dataset has been
  temporarily removed from \texttt{unmarked} until full permission can
  be secured.}, which is a list with two
components. The first component, \verb+crossbill+, is a data.frame
containing the
detection/non-detection data and some covariates such as the percent
cover of forest at each survey location. %The second component,
%\verb+switzerland+, is a list with two matrices defining the
%covariates: elevation and forest cover. Each matrix can be
%converted into a raster using the \texttt{raster} package. First, we
%format the crossbill data and fit the model. For additional details
The following commands format the data and fit the model using the
\verb+colext+ function. For more information
about this model, see the ``colext'' vignette that comes with
\texttt{unmarked}.


<<eval=false,echo=false>>=
data(crossbill)
crossbill <- crossbill.data$crossbill
years <- as.character(1999:2007)
years <- matrix(years, nrow(crossbill), 9, byrow=TRUE)
umf <- unmarkedMultFrame(y=as.matrix(crossbill[,5:31]),
    siteCovs=crossbill[,2:3], yearlySiteCovs=list(year=years),
    numPrimary=9)
(fm <- colext(~ele + forest, ~ele + forest, ~1, ~1, umf))
@
\begin{Schunk}
  \begin{small}
\begin{Sinput}
> data(crossbill)
> crossbill <- crossbill.data$crossbill
> years <- as.character(1999:2007)
> years <- matrix(years, nrow(crossbill), 9, byrow=TRUE)
> umf <- unmarkedMultFrame(y=as.matrix(crossbill[,5:31]),
     siteCovs=crossbill[,2:3], yearlySiteCovs=list(year=years),
     numPrimary=9)
> (fm <- colext(~ele + forest, ~ele + forest, ~1, ~1, umf))
\end{Sinput}
\begin{Soutput}
colext(psiformula = ~ele + forest, gammaformula = ~ele + forest,
    epsilonformula = ~1, pformula = ~1, data = umf)
Initial:
            Estimate       SE     z  P(>|z|)
(Intercept) -3.28709 0.519357 -6.33 2.47e-10
ele          0.00107 0.000359  2.97 2.93e-03
forest       0.02944 0.006087  4.84 1.32e-06

Colonization:
             Estimate       SE     z  P(>|z|)
(Intercept) -2.378039 0.411148 -5.78 7.30e-09
ele         -0.000323 0.000287 -1.12 2.61e-01
forest       0.023013 0.004290  5.36 8.14e-08

Extinction:
 Estimate    SE     z  P(>|z|)
    -1.46 0.154 -9.45 3.29e-21

Detection:
 Estimate     SE    z P(>|z|)
   0.0955 0.0579 1.65  0.0992

AIC: 5123.448
\end{Soutput}
  \end{small}
\end{Schunk}



Now that we have our fitted model, we can use the estimates to compute
the expected probability of occurrence at each pixel in the
landscape. The \texttt{raster} package makes this easy. Here are the
commands to create raster objects from the covariate matrices that
come with the crossbill data.
<<eval=false,echo=false>>=
library(raster)
elevation <- raster(crossbill.data$switzerland[[1]])
layerNames(elevation) <- "ele"
forest <- raster(crossbill.data$switzerland[[2]])
layerNames(forest) <- "forest"
@
\begin{Schunk}
\begin{Sinput}
> library(raster)
> elevation <- raster(crossbill.data$switzerland[[1]])
> layerNames(elevation) <- "ele"
> forest <- raster(crossbill.data$switzerland[[2]])
> layerNames(forest) <- "forest"
\end{Sinput}
\end{Schunk}
The landscape
extent and the projection were not specified simply because they are
not relevant to our
purposes. The reason for assigning the layerNames is that the
\verb+predict+ function, which will be used shortly, requires that the
rasters have names identical to the names of the variables used in
the model fitting process.

The \verb+predict+ function is useful for computing
spatially-referenced model predictions, standard errors, and
confidence intervals, but it is computationally demanding when
there are many pixels in the raster. Thus, if measures of uncertainty
are not
required, the following code can be used to quickly produce the species
distribution map shown in Fig.\ref{fig:psi1}.

<<psi1,eval=false,echo=false,fig=TRUE,include=FALSE>>=
(beta <- coef(fm, type="psi"))
logit.psi <- beta[1] + beta[2]*elevation + beta[3]*forest
psi <- exp(logit.psi) / (1 + exp(logit.psi))
plot(psi, axes=FALSE)
@
\begin{Schunk}
\begin{Sinput}
> (beta <- coef(fm, type="psi"))
\end{Sinput}
\begin{Soutput}
    psi(Int)     psi(ele)  psi(forest)
-3.287090570  0.001067963  0.029443422
\end{Soutput}
\begin{Sinput}
> logit.psi <- beta[1] + beta[2]*elevation + beta[3]*forest
> psi <- exp(logit.psi) / (1 + exp(logit.psi))
> plot(psi, axes=FALSE)
\end{Sinput}
\end{Schunk}
\begin{figure}[b!]
  \centering
\includegraphics[width=5in,height=5in]{spp-dist-psi1}
\caption{A species distribution map for the European crossbill in
  Switzerland for the year 1999. The colors represent the probability
  of occurrence.}
\label{fig:psi1}
\end{figure}

The same can be done for any other parameter. For example, if we
modeled density, perhaps using the \verb+distsamp+ function, we could
compute the expected number of individuals in each pixel. Another
option with the crossbill data is to map expected colonization
probabilities, which can be accomplished using the following code.

<<eval=FALSE>>=
(beta <- coef(fm, type="col"))
logit.col <- beta[1] + beta[2]*elevation + beta[3]*forest
col <- exp(logit.col) / (1 + exp(logit.col))
plot(col)
@

As of version 0.9-6, the \verb+predict+ method in \texttt{unmarked}
can make predictions using an object of class \verb+RasterStack+ from the
\texttt{raster} package. As mentioned previously, the rasters must be
named, perhaps by using the \verb+layerNames(someraster) <- somename+
method. The object
returned by \verb+predict+ is another raster stack with rasters for
the expected values of the parameter of interest, the standard errors,
and the upper and lower confidence intervals. The following example
is very slow because there are many of pixels in the raster. The
resulting map is shown in Fig.\ref{fig:predict}.

<<eval=FALSE,echo=false,fig=TRUE>>=
rasters <- stack(elevation, forest)
E.psi <- predict(fm, type="psi", newdata=rasters)
plot(E.psi, axes=FALSE)
@
\begin{Schunk}
\begin{Sinput}
> rasters <- stack(elevation, forest)
> E.psi <- predict(fm, type="psi", newdata=rasters)
\end{Sinput}
\begin{Sinput}
> plot(E.psi, axes=FALSE)
\end{Sinput}
\end{Schunk}
\begin{figure}[b!]
  \centering
\includegraphics[width=5in,height=5in]{spp-dist-predict}
\caption{Expected occurrence probability along with standard errors
  and the limits of the asymptotic 95\% confidence interval.}
\label{fig:predict}
\end{figure}

Users should be cautious when predicting from models that have
categorical predictor variables, \emph{i.e.} \verb+factor+s. The
\texttt{raster} package does not have advanced methods for handling
factors, and thus it is not easy to automatically create dummy
variables from them as can typically be done using
\verb+model.matrix+. The safest option is to create the dummy
variables manually before fitting the models, and to use the same
variables as rasters for prediction.



<<echo=FALSE>>=
detach(package:raster)
@


\end{comment}


\newpage

\bibliography{unmarked}

\end{document}
